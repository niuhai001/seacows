




基于超算力数据中台和多模态算法模型的储能电站安全监测预警管控平台技术研究与应用项目
超算力数据中台部署手册































目  录
1 引言	1
1.1 编写目的	1
1.2 编写依据	1
1.3 预期读者与阅读建议	2
1.4 名词术语	2
1.4.1 术语	2
1.4.2 缩略语	4
1.5 需求描述约定	5
2 项目概述	5
2.1 项目背景	5
2.2 项目目标	10
2.3 项目需求	11
2.3.1 开发一套基于超算力的储能数据中台	11
2.3.2 与其他储能安全预警相关模块协同集成研究	11
2.3.2.1 协同集成内容	12
2.3.2.2 协同集成技术要求	12
3 系统概述	12
3.1 产品概述	12
3.2 业务架构	15
3.3 应用架构	15
3.4 技术架构	15
3.5 数据架构	16
3.6 安全架构	18
4 系统部署方案	19
4.1 服务架构说明	20
4.2 物理架构图	21
4.3 数据流向	23
4.4 网络拓扑	24
4.5 IP地址申请清单	26
4.6 场站部署方案	26
4.6.1 站端三区边缘服务器数据采集	26
4.6.2 数据传输路径	27
4.6.3 设备配置	28
4.6.4 软件配置	31
4.6.5 网络配置	33
4.6.6 网络安全	34
4.6.6.1 网络安全部署原则	34
4.6.6.2 网络安全部署	35
5 中台部署手册	37
5.1 安装系统	37
5.1.1 如何安装麒麟系统麒麟	37
5.1.1.1 先登录iBMC	37
5.1.1.2 在首页找见虚拟控制台，进入html5	37
5.1.1.3 在上边找见光驱，把镜像上载到光驱，以光驱为启动项	38
5.2 配置网络	39
5.3 配置自动补全	39
5.4 系统规划	40
5.4.1 配置解析	41
5.4.2 修改主机域名	41
5.4.3 添加密钥	41
5.4.4 关闭防火墙和selinux	42
5.5 部署大数据集群	42
5.5.1 下载包，解压包	42
5.5.2 做软链接	42
5.5.3 配置环境变量	42
5.5.4 创建configs	43
5.5.5 配置指南	44
5.5.5.1 基础配置	44
5.5.5.1.1 配置hadoop	44
5.5.5.1.2 配置yarn	50
5.5.5.1.3 配置spark	61
5.5.5.1.4 配置zookeeper	64
5.5.5.1.5 配置kafka集群	65
5.5.5.2 数据仓&数据库配置	67
5.5.5.2.1 配置hive	67
5.5.6 启动集群	74
5.6 超算力数据中台部署	74
5.6.1 平台配置更新	74
5.6.1.1 平台环境变量配置更新	74
5.6.1.2 安装包分发	74
5.6.2 中间件部署	75
5.6.2.1 shuqi1节点组件安装	75
5.6.2.2 shuqidb节点组件安装	75
5.6.2.3 shuqi2节点组件安装	75
5.6.2.4 shuqi3节点组件安装	75
5.6.3 平台启动	76
5.6.3.1 数据中台服务启动	76
6 注意事项	76
6.1 前提条件	76
6.1.1 环境前提条件	76
6.2 限制与约束	76
6.2.1 资源限制	76
6.2.1.1 硬件资源配置	76
6.2.1.1.1 服务器性能	76
6.2.1.1.2 网络配置	77
6.2.1.2 软件配置	77
6.2.1.2.1 集群配置	77
7 附录	78
7.1 参考文档	78




1引言
1.1编写目的
《需求规格说明书》主要是为基于云边协同的储能场站安全监测预警管控技术研究及应用科研项目所撰写的需求规格说明书，系统包括边缘超算服务和超算力数据中台两部分。
本说明书在于清晰地指导最终用户、开发者完成对本系统规定的边界和目标，描述系统的功能性需求和非功能性需求。功能性需求即系统要实现的功能及概要的界面实现方式。非功能需求包括性能需求、安全性需求、可维护性需求、易用性需求、数据接口需求、设备可靠性需求、其他需求。通过本文档定义的需求，以求在项目组成员与其他相关成员之间达成一致的需求描述。
1.2编写依据
本方案编制参考相关政策文件和技术规范文件如下：
《电化学储能电站运行指标及评价》GB/T36549-2018
《国家发展改革委国家能源局关于加快推动新型储能发展的指导意见》
《国家电网公司“十四五”数字化发展规划》
《国家电网有限公司四届一次职代会暨2021年工作报告》
《国网公司2021年互联网专业工作会议文件》
《2020年电力大数据应用专项行动方案》（国家电网互联〔2020〕271号）
《国家电网有限公司关于印发2019年企业中台建设方案的通知》（国家电网互联〔2019〕571号）
《国网互联网部关于加强数据管理的通知》（互联数据〔2019〕14号）
《企业中台建设工作推进会（第十三期）》
《数据中台状态监测专项工作方案》
GB/T17626.12-2023电磁兼容试验和测量技术振荡波抗扰度试验
GB/T42288-2022电化学储能电站安全规程
GB38031-2020	电动汽车用动力蓄电池安全要求
GB/T12504－90计算机软件配置管理计划规范
GB/T13702-92计算机软件分类与代码
GB/T14079－93软件工程术语
GB/T15629.3－1995中华人民共和国计算机信息安全保护条例
GB/T15532-1995计算机软件单元测试
GB/T4943-1995信息技术设备（包括电气事务设备）的安全
GB/T9385-88计算机软件需求说明编制指南
GB/T9386-88计算机软件测试文件编制规范
GB/T8567-2006计算机软件文档（软件用户手册）编制规范
GB/T12504-90计算机软件质量保证计划规范
GB/T12505-90计算机软件配置管理计划规范
GB/T14394-93计算机软件可靠性和可维护性管理
GB/T8566-1995信息技术软件生存期过程
1.3预期读者与阅读建议
预期读者	阅读建议
业务部门、决策部门、具体的使用部门、业务员、系统管理员	仔细阅读文档约定，系统功能介绍需求描述、非功能需求、非功能需求与功能列表说明。
各个部门可重点阅读与本部门相关的内容。
参加需求评审的人员	仔细阅读与其评审侧重点相关的内容。
系统设计人员	仔细阅读全部内容
系统测试人员	仔细阅读全部内容
系统开发人员	仔细阅读全部内容
1.4名词术语
1.4.1术语
电池管理系统：配合监控储能电池状态的设备，主要就是为了智能化管理及维护各个电池单元，防止电池出现过充电和过放电，延长电池的使用寿命，监控电池的状态。功能包括：基本的电压、电流、电池包温度等的检测、估算SOC、SOH、均衡、电池功率限制、热控制等控制功能、通信、故障诊断及报警。
储能变流器：又称储能逆变器。作为电池和外部交流电的中间件，控制电流是交流->直流还是直流->交流，即控制蓄电池的充放电。
能量管理系统：普遍又称储能监控系统。储能系统就地监控是整个储能系统的高级控制中枢，负责监控整个储能系统的运行状态；是联结电网调度和储能系统的桥梁，起到上传下达的作用：一方面接收电网调度指令，另一方面把电网调度指令按能源管理策略分配至各个储能支路，同时监控整个储能系统的运行状态，分析运行数据，确保储能系统处于良好的工作状态。储能监控系统的主要功能有：SCADA功能、诊断预警功能、全景分析功能、优化调度决策功能和有功无功控制功能，混合储能系统优化管理与控制，储能系统保护与控制。监控系统通过对电池、变流器及其他配套辅助设备等进行全面监控，实时采集有关设备运行状态及工作参数，并上传至上级调度层，同时结合调度指令和电池运行状态，进行功率分配，实现储能系统优化运行。
电化学储能电站：采用电化学电池作为储能元件，可进行电能储存、转换及释放的电站，由若干个不同或相同类型的电化学储能系统，及并网、维护、检修等设施组成。
电化学储能系统：以电化学电池为储能载体，通过储能变流器可循环进行电能存储、释放的设备组合。一般直接被称为储能系统，常见形式是一个集装箱。
电化学储能单元：由电化学电池、电池管理系统、储能变流器组成的，能独立进行电能存储、释放的最小储能系统。
电池剩余容量：SOC(StateOfCharge)表征电池当前的剩余容量，为0-100%之间的数值。
电池劣化程度：SOH(StateOfHealth)主要表征当前电池的健康状态，为0-100%之间数值，一般认为低于80%以后电池便不可再用。
事件顺序记录：SOE，全称为Sequence Of Event，指事件顺序记录，是记录故障发生的时间和事件的类型。比如某开关XX时XX分XX秒XX毫秒发生什么类型的故障，等等；对于SOE来说，为了精确的分辨出各个重要信号的先后，SOE记录必须达到1ms甚至更小的分辨率。
装机功率：一个车间设备的额定功率的总和。
额定功率：电器设备的正常工作功率。
遥信：远程信号。是指采集并传送各种保护和开关量信息。
遥测：远程测量。是指采集并传送运行参数，包括各种电气量(线路上的电压、电流、功率等量值) 和负荷潮流等。
遥控：远程控制。是指接受并执行遥控命令，主要是分合闸，对远程的一些开关控制设备进行远程控制。
遥调：远程调节。是指接受并执行遥调命令，对远程的控制量设备进行远程调试，如调节发电机输出功率。
热失控：由于不当操作等原因，电池内部过热，导致电池内物质活性升高，发生一系列化学反应，进一步升高电池温度，最终引发燃烧爆炸等事故。
1.4.2缩略语
中文全称	缩略词
电池管理系统	BMS
储能变流器	PCS
能量管理系统	EMS
电化学储能电站	EESS
电化学储能系统	ESS
电化学储能单元	ESU
电池剩余容量	SOC
电池劣化程度	SOH
最大功率点跟踪太阳能控制器	MPPT
工控机	IPC
直流	DC
交流	AC
SEI膜	SEI
循环深度	DoD
系统能效比	PR
能量利用率	EBA
时间可利用率	TBA
事件顺序记录	SOE
不间断电源	UPS
自动发电控制	AGC
自动电压控制	AVC
远动系统（数据采集与监视控制系统）	SCADA
遥信	YX
遥测	YC
遥控	YK
遥调	YT
断路器	CB
绝缘栅双极型晶体管IGBT	IGBT
1.5需求描述约定
需求层次划分	分三个层次，用三位字符表示。第一层需求指主功能模块，第二层指功能模块的主功能点，第三层指主功能点下的具体需求。
需求跟踪粒度	跟踪到第二层功能需求。
需求级别定义	本文档统一规定对需求层次为二级以上（功能模板、主功能点）的定义优先级，三层需求依据二层需求的优先级执行。
本文档的优先级别分为：高、中、低。
功能描述方法	本文档从以下几个方面对功能需求进行描述：
业务定义/描述；
适用的用户类；
业务规则/业务要素；
输入：提供所有与本功能有关的输入描述，包括：输入数据类型、媒体、格式、数值范围、精度、单位等；
输出：提供与本功能有关所有输出的描述，包括：输出数据类型、方式、格式、精度、单位等，以及图形或显示报告的描述；
业务操作流程。
界面描述规则	界面使用Axure制作的界面原型进行描述。
2项目概述
2.1项目背景
随着我国综合国力的发展，全社会总耗能量不断攀升。全社会用电总量指标方面，综合电气化等因素，总体保持增长且速度呈现“前高后低”趋势。在“十四五”和“十五五”期间（前段），分别以4.5%和3.5%年均增速保持稳定增长，至2030年达到11.1万亿千瓦时的水平。2030~2050年（中段），年均增长率逐步下降，2050年全社会用电量为当前水平的2倍，约为16万亿千瓦时。2050~2060年（后段），增速进一步放缓，2050~2055年间年均增速仅为1%，2055年后基本保持稳定不再增长。
基于上述能源电力发展需求，预估2020~2060年我国电力装机及发电结构，由此得到风光发电量、煤电发电量、非化石能源发电量占比等关键参数演化趋势。
电力装机方面，随着风光等新能源发电快速发展，非化石能源发电在电力装机总量的占比在持续提高，“十四五”末将超过50%。新能源发电装机不断增加，2025~2030年间，风光装机总量超过煤电，2030年将达到16.1亿千瓦，占装机总量41.5%；2035年达到24.3亿千瓦，超过电力装机总量的50%，成为装机主体；2060年达到70.1亿千瓦，在电力装机总量中的占比超过85%。
发电量方面，2030~2035年非化石能源年发电量超过50%，形成非化石能源发电为主体的电力系统；风光发电量快速提升是非化石能源发电量占比提高的主要原因，2030年风光发电量达到2.3万亿千瓦时，占总发电量20%；2035~2040年间风光发电量开始超过煤电，之后煤电进一步加速退役，风光发电量在总发电量中占比加速提高，2045~2050年间z超过50%，成为发电主体；2060年风光发电量11.9万亿千瓦时，占总发电量69.2%，为构建以新能源为主体的新型电力系统创造必要条件。
针对上述我国能源电力发展场景，通过初步测算能源电力系统的年碳排放指标，可得到以下结论：能源系统和电力系统的年碳排放均可实现2030年前达峰，2050年和2060年，能源系统年碳排放分别降低为峰值的28.0%、10.5%，电力系统碳排放分别降低为峰值的25.4%、1.6%，为实现2060年前碳中和目标奠定基础。
在一系列国家战略规划指导下，我国未来综合能源系统的发展蓝图和关键技术途径有了明确的导向性，即以“2030年前碳达峰、2060年前碳中和”为战略目标，以落实“构建清洁低碳安全高效的能源体系、构建以新能源为主体的新型综合能源系统”为实施路径。从综合能源主要特征和核心指标出发，构建“双碳”目标下我国综合能源系统发展情景。
储能是支撑新型电力系统的重要技术和基础装备，对推动能源绿色转型、应对极端事件、保障能源供应安全、促进新能源高质量发展、实现碳达峰、碳中和具有重要意义。但目前受各种因素条件的制约，储能相对规模较小，在新型电力系统中对弃风、弃光、增强电网稳定性的作用相对有限，储能的实际工况数据难以发掘，导致储能的真实工况难以监测，对储能投运后的运维工作产生了较大影响。因此，亟待针对以储能运行数据为基础，进行基于数据驱动的储能系统运行状态智能评估技术研究及应用。
目前规模化储能系统的运维评估主要依靠基于实验室的电池评估方法和模型来进行储能系统状态评估。但已有实验方法和模型往往根据设定的单一工况或工程需求模拟工况来开展，而工程应用中储能系统是按照电网的实时调控指令来运行的，这就造成对储能系统状态的评估误差不断增大，不利于储能电站的精准调度及运维。
随着“十四五”规划的发布及全国储能装机规模的不断增大，在储能大规模装机的背景下，针对储能系统内部实际工况监测的分析的需求日益凸显，储能系统在投建、并网、运行、退役整个生命周期内，保障储能系统安全运行，监测优化储能系统充放效率是促进储能系统与大电网友好协同的重点工作。因而对储能系统的精准运行状态评估技术研究是基于当前国家电网公司实际情况考量下的未来重点发展方向规划。
能源危机使锂离子电池储能系统在过去几年得到了更加广泛的使用，但也出现了一些危险事故造成设施和环境的损坏，经济损失、甚至人员伤亡。调查发现即使储能系统已符合电池系统相关的标准，如UL9540和UL9540A，但还是发生了热失控以及火灾。因此，从以往的案例中吸取经验教训，分析风险及其对策，将有利于储能系统技术的后续发展。
储能电站热失控发生火灾的诱因主要来源于两点：
1.内部电芯失效，引发电池与模组的热失控，最后引起整个储能系统的着火或爆炸
电芯热失控引发的故障呈现的现象基本上是先起火再爆炸：如，2019年发生在美国亚利桑那州的McMicken电站和2021年中国北京丰台电站事故均是在起火后发生爆炸；这种现象产生的原因是单个电芯失效，引发内部化学反应，释放热量(放热反应)，温度持续上升，且传播到附近的电池和模组，引发火灾甚至爆炸。电芯的失效模式一般由过充或控制系统故障、热暴露、外部短路和内部短路(可由各种情况引起，如压痕或凹痕、材料杂质、外部物体渗透等)引起。
电芯热失控之后会产生可燃气体。可以看到前三起案例发生爆炸的原因都是可燃气体不能及时排出而引发的。此时电池与模组，集装箱的通风系统则显得格外重要。一般电池是通过排气阀排出气体，排气阀的压力调节可以减少可燃气体的堆积。模组阶段一般会使用外部风扇或外壳自身散热设计来避免可燃气体聚集。最后在集装箱层面，也需要有通风设施及监测系统来疏散可燃气体。
2.外部辅助系统故障引发的储能系统故障
由辅助系统故障而引发的整个储能系统故障一般发生在电池系统的外部，可能会发生外部元器件的燃烧或冒烟，当系统及时监测与响应后，不会对电池系统的电芯产生失效或热失控的影响。在2021年VistraMossLanding1期和2022年的2期事故中，由于当时在调试阶段，故障监控和电气故障安全装置被关闭，无法及时响应，才产生了冒烟与火灾。这种火焰燃烧通常从电池系统外部开始，最后才会蔓延到电芯内部，所以不会发生剧烈的放热反应与可燃气体聚集的情况，通常不会发生爆炸。且如果此时喷淋系统能及时开启，也不会造成大面积的设施损坏。
而2021年在澳大利亚吉朗发生的“Victorian电站”火灾是由于冷却剂泄漏引起的电池短路，造成起火。此时电池系统的物理隔离也是值得我们注意的地方。外部设施最好与电池系统保持一定的独立空间，避免相互干扰。电池系统最好自身也保持一定的绝缘功能，避免外部短路。
储能系统的运行数据能够反映其运行性能与健康状态，通过开展储能系统运行数据的挖掘和分析，掌握储能系统的运行特性，建立基于运行轨迹的储能系统状态评估方法，并结合大数据、人工智能、云平台的多时间多空间尺度的多模型信息融合，展开多层级、多维度的电池储能系统建模、预警及保护，可极大提高电池储能系统的安全运行及实时保护，为电池储能系统更大规模的安全应用提供坚实的技术保障。
在储能全生命周期的管理监测维度上，基于先进的纳米微粒子技术，研发储能安全监测领域的专用装置，设计多模型驱动的高精度状态估计算法，构建电池储能系统的全息图，设计面向锂电池多源融合状态监测的大数据存储平台，搭建储能电站安全监测预警管控平台对整个储能系统的稳定安全高效运行有着突出作用。
在储能电站运行阶段，通过开展储能系统运行数据的挖掘和分析，使用时序检测、数据分解、聚类建模、数据重构，建立储能数据智能分解与重构的数据预测能力，使用储能系统评估方法，在运行上实时对储能系统进行状态评估，在预测上对储能系统的未来运行轨迹趋势进行分析展示。在运行阶段上，对储能实际运行状况做到全面监测分析。
据预测，中国投运的新型储能项目规模将于2025年底达3000万千瓦。中国光伏发电、风力发电等新能源电站/基地的建设规模也将持续扩大。国家出台的相关政策中，明确表示通过“大力推进电源侧储能项目建设、积极推动电网侧储能合理化布局、积极支持用户侧储能多元化发展”鼓励储能发展，预计将在电网侧储能项目以及新能源发电侧储能项目中有较大的需求，通过技术咨询、技术服务、产品销售等手段进行技术成果推广，具有可观效益。
随着大规模储能电站的快速发展，规范化的运维方法已经成为储能电站维护人员日益迫切的实际需求。国内的储能电站建设规模持续增大，电池储能电站运维成本高、工作量大且运维数据利用价值小的问题亟待解决。国际上已建成的储能示范电站对于储能电池的全寿命周期评价方法及指标，均处于技术保密状态，外界无法获取任何相关资料和信息。国内对于这方面的研究刚刚起步，但是多家企业均在积极进行储能电站智能运维的研究，如中国电科院在这方面通过张北储能试验基地的建设和相关储能并网实验积累了一定的技术基础和相关数据。
在发展的过程中，电化学储能技术为主的储能电站仍存在安全性方面的上升空间。在长时间运行的过程中，储能电站面临着较为严重的安全问题，如电化学储能电池的异常及故障会导致热失控等严重问题。储能电站安全问题已成为限制其进一步应用发展的关键和难点。在电化学储能电站向更大规模集成的进程中，对其实时监测、预警以及管控已成为不可忽视的重点环节。
因此，针对储能电站的运行状态估计和预警问题，本项目围绕大数据和人工智能驱动下的储能电站异常监控和预测的技术展开研究和实践。一方面，通过长期多维度电站运行的历史数据，探索总结异常状态的发生规律，对异常发生做出中长期的提早预判。另一方面，通过数据和物理模型的混合方法，提升电池健康状态的估计计算。所提出方法将直接通过线上实施案例精确度和效率等指标。
综上所述，预警管控机制及应用成为储能进一步应用发展的关键和难点。特别是在电化学储能电站向更大规模集成的进程中，开发基于新型智能传感技术的大规模电化学储能系统全息实时监测，结合大数据、人工智能、云平台的多时间多空间尺度的多模型信息融合，展开多层级、多维度的电池储能系统建模、预警及保护，可极大提高电池储能系统的安全运行及实时保护，为电池储能系统更大规模的安全应用提供坚实的技术保障。
本项目旨在设计面向锂电池储能系统多源融合背景下，研究支持海量储能数据存储、传输、读取的超算力数据中台，形成适应未来储能电站发展的储能超算力大数据中台能力，同时，基于储能数据中台进行多模态算法模型的储能电站安全监测预警平台研究，融合三峡电能内现有其他新能源功能模块，为全面提升储能电站用能安全以及为双碳进程提供有力支撑。
2.2项目目标
本项目旨在设计面向锂电池多源融合状态监测的超算力数据中台，搭建储能电站安全监测预警管控平台，融合集成多场景下预警管控模块，为全面提升储能电站用能安全提供有力支撑，主要研究目标如下：
（1）基于超算力数据中台，实现储能电站全生命周期数据的秒存秒算秒查
（2）储能电站安全监测预警管控平台
与三峡电能能管云·轻舟版平台结合，实现BMS报警量、烟感报警量、温感报警量、微纳米粒子的浓度、特征气体浓度等指标参数的接入，实现多模型驱动的锂电池高精度估计算法部署。在管控平台端进行数据分析与不同层级故障预警监测，实现储能电站锂电池故障多等级故障预警。形成自主知识产权成果。
申请发明专利4项、申请实用新型专利5项、获得软件著作权10项、发表论文1篇。
2.3项目需求
2.3.1开发一套基于超算力的储能数据中台
超算力数据中台是安全监测预警管控平台的数据处理中枢，通过集成的数据采集能力，汇聚储能电站各类数据至存储层，经过清洗加工、实时转换，形成标准数据模型，应用扩展卡尔曼滤波(EKF)、Pytorch 深度学习算法、安时积分法（AH）等多种算法模型，满足全站全测点数据的秒存·秒查·秒算需求。同时根据储能业务能够进行数字化、智能化处理，实现多维度、多元数据的融合、共享、分析。超算力储能数据中台技术研究包括以下几点：
安全性：基于超融合技术，设计一套数据级的容灾备份机制，提升中台系统整体可靠性；
实效性：集超算和超融合先进技术，研发可支持700万点/秒数据容量的全量·全点·全生命周期(25年)的1秒级采集、1秒级存储、1秒级计算、秒级随机关联查询超算以及数据的标准化标签化可视化智能化和数据资产管理能力。同时形成庞大的数据湖，高效为单体电池的数据监测、SOC估算、故障预警、数据分析预测等核心储能应用提供实时数据服务；
扩展性：设计一套可横向弹性扩展的中台架构，采集和数据库的容量在设计上无限制，充分考虑本项目未来的扩容需求，以满足储能电站的应用建设。
超算力数据中台是基于超融合底座研制的一套数据全量、全点、全生命周期管理的统一数据平台，支撑设备、数据、服务互联互通的标准体系，整合上下游产业链、重构外部生态。本架构需具备状态全面感知、信息高效处理、应用便捷灵活的特性，同时打破专业壁垒，消除信息孤岛，增强数据共享服务能力。提供的技术能力包括：数据采集接入，数据清洗，实时存储，业务算子，BI可视化开发，统一门户管理，数据资产化，数据服务及数据可视化能力等。适用于将海量分散的数据集中高效处理，避免数据孤岛，快速响应应用需求，提升数据价值。同时能够形成统一技术体系、统一数据接口、统一运维服务。
2.3.2与其他储能安全预警相关模块协同集成研究
基于超算力储能数据中台和多模态算法模型的储能电站安全监测预警管控平台需在遵循网络安全、系统安全、数据安全的基础上研究与其他储能安全预警相关模块协同集成的方案，包括与储能安全预警相关模块课题的协同集成研究，形成云边协同的储能安全预警全流程闭环课题研究。
2.3.2.1协同集成内容
（1）包括与三峡电能能管云·轻舟版平台进行系统集成工作，实现综合能源平台与储能电站安全监测预警管控平台的数据互通、系统融合。
（2）包括与储能安全预警相关模块课题的协同集成研究，形成云边协同的储能安全预警全流程闭环课题研究。
2.3.2.2协同集成技术要求
与三峡电能能管云·轻舟版平台进行系统集成时，需达到如下要求：
满足系统易用性、扩展性、安全性
与三峡电能能管云·轻舟版平台集成时，需兼顾其他储能安全预警模块。
与其他安全预警模块集成或只提供数据接口时，需提供相关技术协议文档、接口文档等。
需阐述相关安全预警模块与本课题的逻辑关联关系和集成研究路径。
3系统概述
3.1产品概述
超算力数据中台采用云边一体的分布式时序数据库(DTS-DB)作为核心技术，通过数据库日志同步技术，引入差分算法，针对电池数据进行压缩处理，实现站端数据和云平台数据的高效同步。时序数据的分布式聚合计算需要多个节点并行计算，逻辑上也是一个Map/Reduce的过程，Map过程需要对原始时序数据进行分片，分别聚合计算。Reduce过程则是对多个分片计算结果的合并。往往聚合运算的结果和原始数据有着明显数据量的差距，其次分布式计算可以更多的考虑数据的本地化，因此使用分布式聚合计算显然能够有效提高查询性能。
时序数据要进行分布式计算需要解决两个基本问题：时序数据计算分片以及计算结果的合并。
时序数据聚合计算的分片可以分为几个维度考虑：存储分片、聚合函数时间窗口以及查询条件。
首先，时序数据聚合查询包含多种条件，对时序数据进行分组聚合查询也是一种常用查询，不同的分组原始时序数据不同，因此可以通过查询分组对时序数据计算进行分片，不同的分组使用不同节点并发计算。
其次，时序数据聚合查询函数通常都包含时间窗口，相同时间窗口的原始数据聚合计算为一个数据点，不同的时间窗口用于计算的时序原始数据不同，因此也同样可以通过时间窗口对时序数据计算进行时间维度的分片，不同的节点计算不同时间窗口的数据。
第三，按照存储分片进行计算。我们先来回忆一下前文说描述的时序数据的存储，时序数据由于存储的数据量很大，单机并不能满足需求，因此需要对时序数据进行分片存储，分片(shard)通常使用metric+的方式进行，不同的分片存储在不同的存储节点，分片存储着原始时序数据，使用存储分片进行分片计算，也是一种自然而然的选择。如下图先对shard进行分片计算查询，最后对结果进行合并。时序数据分布式计算流程如下图所示。

时序数据分布式计算流程图
使用存储分片来分片计算有着什么优势呢？显然，数据查询和计算在存储分片的节点上进行，能够最大的保证数据本地化，能够有效减少网络通讯带来的延时，使得本地数据计算更加高效。
分布式聚合查询在实现时，往往多种计算分片方式同时使用，聚合计算尽量保证本地化、尽量多的并发执行。
时序数据聚合计算结果的合并和计算分片的方式有相关性，不同分片方式结果的合并方式也不同。
首先，对于分组聚合查询结果的合并来说，不同的分组查询结果属于不同的分组，按照分组聚合查询条件合并结果，就能形成计算结果。
其次，对于聚合函数时间窗口分片查询的合并来说，不同的时间窗口的计算结果虽然属于同一个分组，但是结果在时间是上有序的，因此只需要对分片计算结果按照时序排序合并，就能获取最终计算结果。
第三，对于存储分片进行分片计算结果的合并来说，合并相对复杂，因为在同一个时间窗口内，可能会包含多个分片，多个分片上同一时间窗口需要聚合运算为一个数据点。聚合运算结果的合并就需要分析聚合函数的特性来进行，例如在A和B两个存储分片的同一时间窗口内SUM聚合函数，显然计算结果可以直接累加SUM(A U B) = SUM(A) + SUM(B)，但是并不是所有的聚合函数都满足这一特性，需要根据聚合函数的特性做一一的分类。
当使用多种分片方式进行聚合查询时，相应结果的合并也同样更为复杂。
嵌套聚合查询也是数据分析的常用方式，嵌套聚合运算往往多个聚合函数嵌套而成，每个聚合函数的计算属性并不完全相同。在考虑计算分片时，可以考虑将外部嵌套函数和内部嵌套函数分开计算，选择更加有利的分片方式。例如考虑 DIFF(SUM(A, 1day)) 嵌套聚合函数（DIFF聚合函数是计算前后时间序列结果的差值），既可以使用按照时间窗口的方式分片计算，也同样可以考虑将 DIFF的计算和SUM的计算拆分开来，先使用存储分片的方式聚合计算SUM(A, 1day)的结果，结果合并时计算DIFF嵌套聚合函数的结果，存储分片的分布式计算能够充分利用数据本地化的特性，因此使用后者显然更加高效。
3.2业务架构

业务架构图
3.3应用架构

应用架构图
3.4技术架构
本数据中台采用云边一体的先进架构，旨在实现场站数据的高效采集、整理、传输与计算。
场站端（边）
部署了多台高性能服务器，负责实时采集场站数据，通过整理和优化，将数据以高效的方式传输至云端。中台通讯组件确保了数据传输的稳定性和实时性，有效提升了数据处理的效率。
陈家冲（云）
第四，数据中台承担着核心的数据处理任务。它接收来自场站端的数据，并利用强大的Storage服务进行海量数据的存储。Thing服务提供高效查询接口，确保业务方能够迅速获取所需数据。同时，数据同步服务将电站数据同步至Hive中，分布式计算框架和标段一算法，数据中台能够对电芯数据进行高效计算，快速生成预警结果，为业务应用提供有力支持。总体而言，本架构实现了海量数据的存储、查询、计算功能，为业务应用提供了强大的数据支持。数据中台架构如下图所示。

数据中台架构图
3.5数据架构
在数据应用层，我们主要利用电站的源数据进行各种计算与分析，以产生预警管控结果。这一层在业务层对电站数据进行处理以满足不同业务场景的需求。此外，应用层还负责将处理后的数据以可视化的形式展示给业务人员，帮助他们更好地理解数据、发现潜在问题，并据此做出决策。预警管控结果的产出是这一层的核心价值所在，它通过对电站运行数据的监控与分析，及时预测异常情况，并触发相应的预警机制，从而确保电站的安全稳定运行。
数据存储
数据存储层是数据架构中至关重要的一环，Storage负责对电站数据进行持久化存储和高效管理。我们采用智能差分算法对海量电站数据进行存储和查询优化，以确保数据的高效访问和快速响应。同时，我们在Hive中存储了计算标段一算法所需的临时数据以及预警结果，以便后续的分析和挖掘。此外，我们还通过数据备份和容灾机制，确保数据的安全性和可靠性。
第五，数据采集传输层位于整个数据架构的最底层，负责在场站端进行数据的采集、整理和传输。在这一层，我们通过采集设备实时获取电站的运行数据，并将其传输到数据中心进行后续处理。同时，为了减轻数据存储和传输的压力，我们还采用压缩后再传输机制。在传输过程中，我们采用了安全可靠的传输协议和加密技术，确保数据在传输过程中的安全性和保密性。数据采集架构如下图所示。

数据采集架构图
在本系统中，数据流转始于站端EMS和消防主机的数据采集。这些原始数据首先被采集服务器接收，确保数据的准确性和实时性。随后，采集服务器将收集到的数据发送至汇聚服务器进行集中处理，通过高效的数据汇聚技术，对数据进行整合和初步处理。
经过汇聚的数据通过通讯服务进行快速、稳定地传输，最终到达云端。在云端，数据被存储在Storage系统中，实现持久化存储，确保数据的安全性和可靠性。
业务应用通过Thing服务接口，可以方便地查询Storage中的设备数据，为业务决策提供数据支持。同时，云端数据同步服务将电芯数据同步到Hive中，利用分布式计算框架结合特定算法，对电芯数据进行深度分析，计算出预警数据。
第六，最终，这些预警数据被提供给业务平台，以直观、易懂的方式展示给用户，帮助用户及时发现潜在风险，确保系统的稳定运行。整个数据流转过程高效、安全、可靠，为系统的智能化、自动化管理提供了有力支持。数据流转架构如下图所示。

数据流转图
3.6安全架构
数据传输安全
(1)使用内网传输。
(2)数据传输加密的主要目的是确保数据在传输过程中的安全性、完整性和保密性。通过SSL加密技术，原始数据（明文）被转换为加密后的数据（密文），以防止数据在传输过程中被未经授权的第三方截获和窃取。
数据容灾
(1)Ceph在数据分布和存储过程中采用了冗余备份机制，确保数据的可靠性和容错性。
(2)每个对象都会被复制到多个存储节点上，形成数据的冗余备份，用户可以根据需求设置副本的数量和位置。
(3)通过心跳机制和故障检测算法来监测存储节点的状态，一旦发现节点故障或数据错误，系统会自动进行数据恢复和修复。
(4)Ceph支持快照技术，管理员可以利用快照进行Image的异地备份和容灾。
存储安全技术架构如下图所示。

存储安全技术架构
4系统部署方案



1.储能电站安全监测预警管控平台、数据中台部署在陈家冲数据中心。
2.在DMZ区向三峡电能能管云·轻舟版申请能管云·轻舟版虚拟服务器，部署Nginx服务做流量转发。
4.1服务架构说明
超算力服务器5台，每台配置如下：
cpu：64c；
内存：256G；
存储：2块960G固态+5块10T机械；

   
服务架构说明：
(1)陈家冲数据中心：部署数据中台，储能电站安全监测预警管控平台
数据中台：物联网数据库、中台Hadoop、中台Web UI。
储能电站安全监测预警管控平台：前端、 后端。
(2)DMZ区: 部署Nginx转发流量。
4.2物理架构图
  
物理架构说明如下：
(1)DMZ区：申请一台能管云·轻舟版虚拟服务器做Nginx转发。
(2)陈家冲数据中心：放置超算力服务器。
(3)二次舱：放置边缘服务器15台。
4.3数据流向

数据流向架构图说明如下:
(1)一区：数据产生是由原始数据和EMS系统来提供，EMS系统的数据将数据推送到边缘服务器（采集系统1），用104协议通过隔离装置传到汇聚服务器。
(2)二区：消防系统用MQTT协议将数据推送到边缘服务器（采集系统2），由边缘服务器（采集系统2）通过正向隔离装置传输到边缘服务器（汇聚系统）
(3)安全生产三区：数据汇聚到边缘服务器（汇聚系统）,边缘服务器（汇聚系统）通过防火墙到达数据中台。
(4)陈家冲数据中心：由储能电站安全监测预警管控平台做展示和管理。

4.4 网络拓扑
经过对于超算力数据中台及储能电站安全监测预警管控平台的网络部署架构的线上会议需求调研后，了解到三峡电能内部及场站的数据网络安全现状的部署，基于本次调研结果，梳理的超算力数据中台及储能电站安全监测预警管控平台的相关图示如下:

网络架构说明：
(1)储能EMS系统走104协议收集到EMS数据，通过正向隔离装置上传到汇聚服务器。
(2)消防系统走MQTT协议，收集到消防数据，边缘服务器通过正向隔离装置将数据传输到汇聚服务器
(3)汇聚服务器通过防火墙走5G的方式将数据传输到陈家冲数据中心。
(4)DMZ区的Nginx到陈家冲数据中心走HTTPS协议通过防火墙访问预警管控平台。
4.5IP地址申请清单
说明：服务器1、服务器2、服务器3、服务器4、服务器5，在同一个网段。
服务器名称	IP作用	IP
服务器1	场站上传的数据需要接入该服务器。该服务器放置在陈家冲。	10.68.23.81
服务器2	场站上传的数据需要接入该服务器。该服务器放置在陈家冲。	10.68.23.82
服务器3
	场站上传的数据需要接入该服务器。该服务器放置在陈家冲。	10.68.23.83
服务器4	场站上传的数据需要接入该服务器。该服务器放置在陈家冲。	10.68.23.84
服务器5	场站上传的数据需要接入该服务器。该服务器放置在陈家冲。	10.68.23.85
场站汇聚服务器	将场站数据上传至陈家冲的服务器	10.68.23.86
4.6场站部署方案
4.6.1站端三区边缘服务器数据采集
储能EMS系统走104协议将数据推送到一区边缘服务器，消防系统通过MQTT协议将数据推送到二区边缘服务器，一区和二区的边缘服务器通过隔离装置将数据传输到站端三区汇聚服务器。网络架构图如下：

场站架构拓扑图
4.6.2数据传输路径
EMS数据：储能电站I区采集边缘服务器（采集EMS系统数据）—>正向隔离装置—>III区汇聚服务器。
储能舱环境安全隐患监测数据：储能电站I区采集边缘服务器—>正向隔离装置—>Ⅲ区采集边缘服务器—>III区汇聚服务器。
消防数据：储能电站II区采集边缘服务器（采集消防系统数据）—>正向隔离装置—>III区汇聚服务器。
4.6.3设备配置
设备名称	型号/配置	备注	个数
边缘超算服务器	型号：SICCYK-I51182-L4R6
配置：
1.基于Intel第11代10nm制成TigerlakeUP3平台；
2.支持9〜36V宽压DC-in输入；
3.最多支持8C0M，COM口支持RS232/422/485口；4.支持1x2.5GbE速度Intel网口以及3x1GbE速度Intel网口；
5.支持VGA，HDMI双显；
6.支持M.22280存储接口支SATA/PCIex4NVMeSSD；		17
正向隔离装置	型号：TY6000-FF
配置：
1.网络接口：6个RJ45(内网×2、外网×2、热备×1、管理×1)；
2.网络接口速率：10MBASE/100MBASE；
3.串行通信接口：2个RS-232（RJ45接口）；
4.贮存温度：-20℃～+55℃；
5.工作温度：-5℃～+45℃；
6.供电电源：220V±15%，50Hz，连续工作；
7.功耗：≤50W；
8.体积：19寸标准机箱，可上机柜；
9.带宽：80Mbps；
10.平均无故障时间(MTBF)：≥50000小时(100%负荷)；
11.延时：小于1毫秒；		1
交换机	型号：华为S5731-H24HB4XZ
配置：
1.20个1/2.5GE光电混合端口(PoE )，4个2.5/10GE光电混合端口(PoE)，4个万兆SFP+；
2.尺寸要求：442x420x43.6；
3.扩展插槽：1个扩展插槽，支持2*40GE、8*10GE或2*25GE光口子卡；
4.电源类型：600WAC电源、1000W PoE AC电源、1000 W PoE DC电源；		1
防火墙	型号：华为USG6311E
配置：
1.2*GEWAN+8*GECombo+2*10GESFP+,1交流电源,含SSLVPN100用户		1
交换机	型号：TL-SG2216 tplink
配置：
1.提供14个10/100/1000M自适应RJ45端口和2个千兆SFP端口；
2.工业级工作温度：-40℃~75℃；
3.宽电压输入：9.6V~60VDC；
4.整机最大功率： 17.28W		1
舱级探测装置	型号：AQ-CJ-01
配置：
1.微粒子直径探测范围：2纳米～20微米；
2.微粒子探测分辨率：500颗/cc；
3.环境温度监测：范围：-20℃~60℃；
4.精度：±1℃；
5.分辨率：0.5℃；
6.环境湿度监测：范围：0~95%RH；
7.精度：±5%RH；
8.分辨率：1%RH；
9.一氧化碳监测：范围：0~1000ppm；
10.灵敏度：1ppm；
11.采样方式：24h实时主动吸入式采样；
12.通信方式：无线/RS485/以太网；
13.通信协议：4G、ModBus、TCP/IP；
14.输入输出：干接点2个以上；
15.显示屏尺寸：7寸 LCD触摸屏；
16.工作电源：AC220V/DC24V；
17.电磁兼容防护等级：EMC四级	内置嵌入式软件	6
簇级主动式安全探测装置	型号：AQ-CJ-02
1.微粒子直径探测范围：100纳米～20微米；
2.微粒子探测分辨率：1万颗/cc；
3.环境温度监测：范围：-20℃~60℃；
4.精度：±1℃；
5.分辨率：0.5℃；
6.环境湿度监测：范围：0~95%RH；
7.精度：±5%RH；
8.分辨率：1%RH；
9.一氧化碳监测：范围：0~1000ppm；灵敏度：1ppm；
10.氢气探测：范围：0~1000ppm；灵敏度：1ppm；
11.电解液挥发物探测：范围：0~1000ppm；灵敏度：1ppm；
12.采样方式：24h实时主动吸入式采样；
13.通信方式：无线/RS485/以太网；
14.通信协议：4G、ModBus；
15.输入输出：干接点2个以上；
16.工作电源：AC220V/DC24V；
17.安全资质：EMC四级；	内置嵌入式软件	11
纳米粒子采样器及配件	型号：PJ-CY
配置：
1.名称：PVC管线；
2.颜色：白色；
3.材质：聚氯乙烯PVC；
4.连接：内插；
5.管径：25mm；	每台舱级主动式安全探测装置/套	6
（正向隔离）中安网络隔离传导干扰器	型号：ZK-07
配置：
1.干扰频段：1MHz～1.5GHz；
2.相关强度：>正常传输信号3db；
3.传输速率：10M/100M/1000M自适应；
4.工作温度：10℃--65℃；
5.电源隔离：10KHz～30MHz，≥40dB；
6.工作湿度：HR--75%；
7.存储温度：-25℃～50℃；
8.工作电压：220V土10%；
9.整机消耗：≤10W；
10.无故障时间	：>5万小时；
11.电源频率：50--60Hz	该产品具有国家保密科技测评中心颁发的《涉密信息系统产品检测证书》可提供证书及检测报告	1
光纤交换机	型号：TL-SG2210工业级
配置：
1.标准：IEEE802.3,802.31.802.3u,802.3x,802.3ab,802.3z；
2.指示灯：支持；
3.DC输入电压：12/24/48 VDC (9.6-60 VDC)；
4.输入电流：0.92A；
5.反接保护：支持；
6.接线端子：6针；
7.IP防护：IP30；
8.产品尺寸(mm)：137*100*38；
9.工作温度：-40'C-75'C；
10.存储温度：40-C-85-C；
11.工作湿度：10%6RH-90%RH，不凝结；
12.存储湿度：596RH-90%RH，不凝结；	1、61、2、62号舱、二次舱内各一个	5
熔纤盒	型号：GXH8SM-SC
配置：
1.尺寸：133x263x40(mm)；
2.挂耳：无挂耳；	8口8芯	5
4.6.4 软件配置
1.在每台设备上安装Linux系统
技术特点
a.系统稳定
b.安全性高
性能
a.支持多任务、多人使用
b.资源消耗相对较低

2.在linux系统安装采集服务
技术特点
a.秒级采集数据
b.安全性高
性能
a.秒级上传
b.资源消耗相对较低

3.安装数据传输服务
技术特点
a.安全可靠的传输链路
性能
b.高性能传输

4.储能安全在线监测预警平台软件
技术特点
a.整个储能电站1套
b.型号：CS-S1000
性能
a.数据采集频率: 有隐患时5 s/次;无隐患时5 min/次；
b.数据量:3.5M/天【按原始30M/30天，业务数据75M/30天预估】
c.数据存储如下：
d.数据库部署：CPU 16C 内存32G硬盘:500G操作系统 麒麟v10；
e.业务应用部署：CPU 16C 内存32G硬盘:300G操作系统 麒麟v10；
4.6.5 网络配置
设备	分配IP	备注
一区边缘服务器	172.121.1.10	申请网安票
	172.121.1.11	
	172.121.1.12	
	172.121.1.13	
	172.121.1.14	
	172.121.1.15	
	172.121.1.16；192.168.1.160	
	172.121.1.18	
二区边缘服务器	192.168.1.40	
	192.168.1.41	
	192.168.1.42	
	192.168.1.43	
	192.168.1.44	
	192.168.1.45	
	192.168.1.46	
三区边缘服务器	172.121.1.31;10.68.23.86	
	192.168.1.60 	
舱级监测终端	192.168.1.112	
	192.168.1.113	
	192.168.1.114	
	192.168.1.115	
	192.168.1.116	
	192.168.1.117	
簇级监测终端	192.168.1.101	
	192.168.1.102	
	192.168.1.103	
	192.168.1.104	
	192.168.1.105	
	192.168.1.106	
	192.168.1.107	
	192.168.1.108	
	192.168.1.109	
	192.168.1.110	
	192.168.1.111	
交换机	192.168.1.1	
	192.168.1.2	
	192.168.1.3	
	192.168.1.4	
	192.168.1.5	
4.6.6  网络安全
4.6.6.1 网络安全部署原则
(1)安全分区
目的：根据三峡扶海储能电站的业务特点和安全需求，将网络划分为不同的安全区域，以实现精细化管理和控制。
安全生产I区：通常包含直接控制生产设备的关键系统，如监控与数据采集系统（SCADA）、能量管理系统（EMS）等，这些系统对实时性和安全性要求极高。
安全生产II区：包含非直接控制生产但影响生产运行的辅助系统，如消防系统、安防系统等，这些系统需要确保数据的完整性和可用性。
安全生产III区：主要为管理、分析和决策提供支持，如数据存储服务器、报表系统等，该区域的数据处理相对灵活，但仍需严格的安全措施。
(2)网络专用
目的：确保各安全区域内的网络资源不被非授权访问和交叉使用，减少潜在的安全风险。
专用化设计：网络设备、系统和服务需满足各自区域的安全标准和要求，如使用专用网络硬件、软件，实施特定的安全策略。
访问控制：通过严格的访问控制机制，限制非授权用户对网络资源的访问。
(3)横向隔离
目的：防止安全威胁在不同安全区域之间横向扩散。
物理隔离：采用物理手段（如物理防火墙、网闸）完全隔离不同安全区域之间的网络连接。
逻辑隔离：通过配置路由、访问控制列表（ACL）等逻辑手段，限制不同区域间的网络通信。
(4)纵向认证
目的：确保数据在纵向传输过程中的安全性。
强身份认证：采用多因素认证、数字证书等强身份认证机制，确保数据传输双方的身份真实可靠。
加密传输：使用SSL/TLS等加密协议，对传输的数据进行加密处理，防止数据在传输过程中被截获或篡改。
4.6.6.2 网络安全部署
(1)安全区域划分与拓扑结构
实施：
三角结构：构建以安全生产III区为顶点，安全生产I区、II区为底边的三角结构拓扑，明确各区域的功能和边界。
物理/逻辑隔离：利用防火墙、正向隔离装置等物理或逻辑设备实现区域间的隔离。
(2)新增采集转发装置部署
目的：提升数据采集的效率和安全性。
设备选型：选择符合安全要求的采集转发装置，具备数据加密、防篡改等功能。
部署位置：根据业务需求，在安全生产I区、II区新增采集转发装置，确保关键数据的全面采集。
(3)正向隔离装置部署
目的：实现数据的单向传输和隔离。
部署位置：在安全生产I区与III区、安全生产II区与III区之间部署正向隔离装置。
功能实现：确保数据只能从低安全区域流向高安全区域，防止数据泄露和非法交换。
(4)交换机部署
目的：实现区域内设备间的网络通信，并增强网络的安全性。
VLAN划分：通过VLAN划分，将同一区域内的设备划分为不同的虚拟网络，提高网络的安全性和灵活性。
ACL配置：配置访问控制列表（ACL），限制不同VLAN之间的通信，防止非授权访问。
(5)数据传输与存储
目的：确保数据在传输和存储过程中的安全性。
加密传输：采用加密技术确保数据在传输过程中的机密性和完整性。
强身份认证：在数据存储服务器上实施强身份认证机制，防止非授权访问。
(6)安全审计与监控
目的：及时发现潜在的安全问题并采取相应的应对措施。
定期审查：定期对安全日志进行审查和分析，及时发现并处理潜在的安全威胁。
(7)培训与意识提升
目的：提高员工的安全意识和操作技能，构建良好的网络安全文化。
定期培训：组织网络安全培训活动，提高员工对网络安全的认识和重视程度。
文化建设：加强网络安全文化建设，鼓励员工积极参与网络安全建设和维护工作。
5中台部署手册
5.1安装系统
5.1.1如何安装麒麟系统麒麟
5.1.1.1先登录iBMC
账号密码    Administrator /  Admin@9000
源密码bios  密码   Admin@90000 
5.1.1.2在首页找见虚拟控制台，进入html5

5.1.1.3在上边找见光驱，把镜像上载到光驱，以光驱为启动项



5.2配置网络
Bash
nmcli connection modify enp125s0f3 ipv4.addresses 10.68.23.81/24 ipv4.gateway 10.68.23.1 ipv4.dns 10.191.16.12 ipv4.method manual connection.autoconnect yes

nmcli connection modify enp125s0f3 ipv4.addresses 10.68.23.82/24 ipv4.gateway 10.68.23.1 ipv4.dns 10.191.16.12 ipv4.method manual connection.autoconnect yes

nmcli connection modify enp125s0f3 ipv4.addresses 10.68.23.83/24 ipv4.gateway 10.68.23.1 ipv4.dns 10.191.16.12 ipv4.method manual connection.autoconnect yes

nmcli connection modify enp125s0f3 ipv4.addresses 10.68.23.84/24 ipv4.gateway 10.68.23.1 ipv4.dns 10.191.16.12 ipv4.method manual connection.autoconnect yes

nmcli connection modify enp125s0f3 ipv4.addresses 10.68.23.85/24 ipv4.gateway 10.68.23.1 ipv4.dns 10.191.16.12 ipv4.method manual connection.autoconnect yes

systemctl restart NetworkManager or  ifdown enp125s0f3   ifup enp125s0f3

5.3配置自动补全
SQL
yum install -y bash-completion
source /usr/share/bash-completion/bash_completion
5.4系统规划
主机名称	目录规划
	服务角色	规格	备注
phy210 shuqi1shuqidbhadoop0	/opt/(应用服务存放位置)
/data/（应用数据存放位置）
	ceph中台 、k8s、network、hadoop 、spark、yarn、zookeeper  预警管控平台后端Mysql、nginx、minio、 elasticsearch、filebeat、registry、redis	cpu：64c
内存：256G 
存储：2块960G固态5块10T机械	
phy211
shuqi2    shuqi3
hadoop1	/opt/(应用服务存放位置)
/data/（应用数据存放位置）	ceph、中台、k8s net2-node、Hadoop、spark、yarn、zookeeper、flink、pushgateway、  node_exporter、grafana、prometheus、mysql	cpu：64c
内存：256G 
存储：2块960G固态5块10T机械	

phy212
hadoop2	/opt/(应用服务存放位置)
/data/（应用数据存放位置）	ceph、k8s、agen、thing  hadoop、hive、spark、yarn zookeeper、kafka、Nginx、mysql 	cpu：64c
内存：256G 
存储：2块960G固态5块10T机械	
phy213
hadoop3	/opt/(应用服务存放位置)
/data/（应用数据存放位置）	ceph、k8s sync、hadoop、 spark、yarn、zookeeper kafka 
	cpu：64c
内存：256G 
存储：2块960G固态5块10T机械	
phy214
hadoop4	/opt/(应用服务存放位置)
/data/（应用数据存放位置）	ceph、k8s、storage hadoop、spark、yarn、 zookeeper、kafka
	cpu：64c
内存：256G 
存储：2块960G固态5块10T机械	

5.4.1配置解析
Bash
cat >> /etc/hosts  << EOF
10.68.23.81 phy210 hadoop0 shuqi1 shuqidb                         
10.68.23.82 phy211 hadoop1 shuqi2 shuqi3 biaoqian mysql-inf.ewc.tgee.com.cn
10.68.23.83 phy212 hadoop2 hadoop-master apiserver.cluster.local
10.68.23.84 phy213 hadoop3 
10.68.23.85 phy214 hadoop4 sealos.hub
EOF
5.4.2修改主机域名
Bash
 hostnamectl set-hostname phy214
 hostnamectl set-hostname phy213
 hostnamectl set-hostname phy212
 hostnamectl set-hostname phy211
 hostnamectl set-hostname phy210
5.4.3添加密钥
Bash
ssh-copy-id -i .ssh/id_rsa.pub phy214
ssh-copy-id -i .ssh/id_rsa.pub phy213
ssh-copy-id -i .ssh/id_rsa.pub phy212
ssh-copy-id -i .ssh/id_rsa.pub phy211
ssh-copy-id -i .ssh/id_rsa.pub phy210
5.4.4关闭防火墙和selinux
Bash
systemctl stop firewalld
systemctl disable firewalld
 vi /etc/selinux/config 
5.5部署大数据集群
5.5.1下载包和解压包
Bash
tar xf apache-zookeeper-3.8.4-bin.tar.gz 
tar xf apache-hive-3.1.0-bin.tar.gz
tar xf hadoop-3.4.0.tar.gz
tar xf spark-2.4.0-bin-hadoop2.7.tar.gz
tar xf kafka_2.12-3.6.2.tar.gz
5.5.2做软链接
Bash
ln -snf apache-zookeeper-3.8.4-bin zookeeper
ln -snf apache-hive-3.1.0-bin hive
ln -snf hadoop-3.4.0 core
ln -snf spark-2.4.0-bin-hadoop2.7  spark
Ln -snf kafka_2.12-3.6.2 kafka
5.5.3配置环境变量
Bash
vim /etc/profile
#export JAVA_HOME=/usr/lib/jvm/java-openjdk
Export JAVA_HOME=/opt/third/jdk

export HADOOP_HOME=/home/hadoop/core
export SPARK_HOME=/home/hadoop/spark
export HIVE_HOME=/home/hadoop/hive
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$SPARK_HOME/bin:$HIVE_HOME/bin:$PATH
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib//native
source /etc/profile
5.5.4创建configs
Bash
Cd /home/hadoop/
mkdir configs
cd  configs
cp -r ../core/etc/hadoop .
cp -r ../hive/conf ./hive
cp -r ../spark/conf ./spark
Bash
vim  dist-conf.sh
# Hadoop: HDFS & YARN
for m in 0 1 2 3 4; do
   echo "dist hadoop conf to hadoop$m"
   rsync -avz hadoop/ root@hadoop$m:/home/hadoop/core/etc/hadoop
done

# Hive
for m in 0 1 2 3 4 ; do
   echo "dist hive conf to hadoop$m"
   rsync -avz hive/ root@hadoop$m:/home/hadoop/hive/conf
done

# Spark
for m in 0 1 2 3 4; do
   echo "dist spark conf to hadoop$m"
   rsync -avz spark/ root@hadoop$m:/home/hadoop/spark/conf
done
#kafka
#for m in  2 3 4; do
#   echo "dist kafka conf to hadoop$m"
#   rsync -avz kafka/ root@hadoop$m:/home/hadoop/kafka/config
#done
5.5.5配置指南
5.5.5.1基础配置
5.5.5.1.1配置hadoop
5.5.5.1.1.1配置hadoop--hdfs-site.xml配置
Bash
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
        <property>
                <name>dfs.nameservices</name>
                <value>ZHDFS</value>
        </property>

        <property>
                <name>dfs.ha.namenodes.ZHDFS</name>
                <value>nn1,nn2</value>
        </property>

        <property>
                <name>dfs.namenode.rpc-address.ZHDFS.nn2</name>
                <value>hadoop2:2220</value>
        </property>

        <property>
                <name>dfs.namenode.rpc-address.ZHDFS.nn1</name>
                <value>hadoop3:2220</value>
        </property>

        <property>
                <name>dfs.namenode.http-address.ZHDFS.nn2</name>
                <value>hadoop2:2270</value>
        </property>

        <property>
                <name>dfs.namenode.http-address.ZHDFS.nn1</name>
                <value>hadoop3:2270</value>
        </property>
<!--
        <property>
                <name>dfs.namenode.servicerpc-address</name>
                <value>hadoop3:8022</value>
        </property>
-->
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/hadoop/meta/nn</value>
        </property>

        <property>
                <name>dfs.namenode.name.dir.nn1</name>
                <value>/home/hadoop/meta/nn</value>
        </property>

        <property>
                <name>dfs.namenode.name.dir.nn2</name>
                <value>/home/hadoop/meta/nn</value>
        </property>

        <property>
                <name>dfs.blocksize</name>
                <value>134217728</value>
        </property>

        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/hadoop/data/hdfs/d0</value>
        </property>
        
        <property>
                <name>dfs.namenode.rpc.max.response.size</name>
                <value>1048576</value>
        </property>

        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>

        <property>
                <name>dfs.replication.max</name>
                <value>512</value>
        </property>
        <property>
                <name>dfs.namenode.shared.edits.dir</name>
                <value>qjournal://hadoop0:2285;hadoop1:2285;hadoop4:2285/ZHDFS</value>
        </property>

        <property>
                <name>dfs.client.failover.proxy.provider.ZHDFS</name>
                <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        </property>

        <property>
                <name>dfs.ha.fencing.methods</name>
                <value>sshfence</value>
        </property>

        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop3:2220</value>
        </property>

        <property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/home/hadoop/meta/jn</value>
        </property>

        <property>
                <name>dfs.journalnode.rpc-address</name>
                <value>0.0.0.0:2285</value>
        </property>

        <property>
                <name>dfs.journalnode.http-address</name>
                <value>0.0.0.0:2240</value>
        </property>

        <property>
                <name>dfs.journalnode.https-address</name>
                <value>0.0.0.0:2241</value>
        </property>

        <property>
                <name>dfs.ha.nn.not-become-active-in-safemode</name>
                <value>true</value>
        </property>

        <property>
                <name>dfs.ha.automatic-failover.enabled</name>
                <value>true</value>
        </property>

        <property>
                <name>ha.zookeeper.quorum</name>
                <value>hadoop0:2281,hadoop1:2281,hadoop2:2281,hadoop3:2281,hadoop4:2281</value>
        </property>

</configuration>

5.5.5.1.1.2core-site.xml
Bash
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop3:2220</value>
        </property>
        <property>
                <name>io.file.buffer.size</name>
                <value>524288</value>
        </property>
</configuration>
5.5.5.1.1.3hadoop-env.sh
Bash
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set Hadoop-specific environment variables here.


export LANG=en_US.UTF-8

export JAVA_HOME=/opt/third/jdk/
#export JAVA_HOME=/usr/lib/jvm/java-openjdk/
export HDFS_NAMENODE_OPTS="-XX:MaxHeapSize=8G -XX:InitialHeapSize=8G -XX:MaxGCPauseMillis=200"
export HDFS_SECONDARYNAMENODE_OPTS="-XX:MaxHeapSize=8G -XX:InitialHeapSize=8G -XX:MaxGCPauseMillis=200"
export HDFS_DATANODE_OPTS="-XX:MaxHeapSize=8G -XX:InitialHeapSize=8G -XX:MaxGCPauseMillis=200"
export HDFS_ZKFC_OPTS="-XX:MaxHeapSize=2G -XX:InitialHeapSize=2G -XX:MaxGCPauseMillis=200"
export HDFS_JOURNALNODE_OPTS="-XX:MaxHeapSize=2G -XX:InitialHeapSize=2G -XX:MaxGCPauseMillis=200"
export YARN_RESOURCEMANAGER_OPTS="-XX:MaxHeapSize=2G -XX:InitialHeapSize=2G -XX:MaxGCPauseMillis=200"
export YARN_NODEMANAGER_OPTS="-XX:MaxHeapSize=2G -XX:InitialHeapSize=2G -XX:MaxGCPauseMillis=200"
5.5.5.1.2配置yarn
5.5.5.1.2.1yarn-site.xml
Bash
<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hadoop2</value>
        </property>
        <property>
                <name>yarn.resourcemanager.address</name>
                <value>hadoop-master:2292</value>
        </property>

        <property>
                <name>yarn.resourcemanager.webapp.address</name>
                <value>hadoop-master:2296</value>
        </property>

        <property>
                <name>yarn.resourcemanager.webapp.https.address</name>
                <value>hadoop-master:2291</value>
        </property>

         <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>hadoop-master:2293</value>
        </property>

        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>hadoop-master:2295</value>
        </property> 
        <property>
                <name>yarn.resourcemanager.scheduler.class</name>
                <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
        </property>
        <property>
                <name>yarn.scheduler.minimum-allocation-mb</name>
                <value>512</value>
        </property>

        <property>
                <name>yarn.scheduler.maximum-allocation-mb</name>
                <value>16384</value>
        </property>

        <property>
                <name>yarn.nodemanager.resource.memory-mb</name>
                <value>196608</value>
        </property>

        <property>
                <name>yarn.nodemanager.resource.cpu-vcores</name>
                <value>48</value>
        </property>
        <property>
                <name>yarn.nodemanager.vmem-pmem-ratio</name>
                <value>1</value>
        </property>
        <property>
                <name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
                <value>100</value>
        </property>
       
        <property>
                <name>yarn.resourcemanager.scheduler.client.thread-count</name>
                <value>1000</value>
        </property>

        <property>
                <name>yarn.resourcemanager.admin.client.thread-count</name>
                <value>1000</value>
        </property>

        <property>
                <name>yarn.nodemanager.local-dirs</name>
                <value>/home/hadoop/data/nm/runtime</value>
        </property>

        <property>
                <name>yarn.nodemanager.log-dirs</name>
                <value>/home/hadoop/data/nm/log</value>
        </property>
        <property>
                 <name>yarn.scheduler.minimum-allocation-vcores</name>
                 <value>1</value>
        </property>
        <property>
                 <name>yarn.scheduler.increment-allocation-vcores</name>
                 <value>1</value>
        </property>
        <property>
                 <name>yarn.scheduler.maximum-allocation-vcores</name>
                 <value>32</value>
        </property> 
 
        <property>
                 <name>yarn.scheduler.capacity.resource-calculator</name>
                 <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
        </property>

        <property>  
                <name>yarn.resourcemanager.max-completed-applications</name>  
                <value>10000</value>  
        </property>

        <property>
                <name>yarn.nodemanager.log.retain-seconds</name>
                <value>604800</value>
        </property>
</configuration>
5.5.5.1.2.2capacity-scheduler.xml 
Bash
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

  <property>
    <name>yarn.scheduler.capacity.maximum-applications</name>
    <value>10000</value>
    <description>
      Maximum number of applications that can be pending and running.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
    <value>0.1</value>
    <description>
      Maximum percent of resources in the cluster which can be used to run 
      application masters i.e. controls number of concurrent running
      applications.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.resource-calculator</name>
    <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
    <description>
      The ResourceCalculator implementation to be used to compare 
      Resources in the scheduler.
      The default i.e. DefaultResourceCalculator only uses Memory while
      DominantResourceCalculator uses dominant-resource to compare 
      multi-dimensional resources such as Memory, CPU etc.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.queues</name>
    <value>default</value>
    <description>
      The queues at the this level (root is the root queue).
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.capacity</name>
    <value>100</value>
    <description>Default queue target capacity.</description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
    <value>1</value>
    <description>
      Default queue user limit a percentage from 0.0 to 1.0.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
    <value>200</value>
    <description>
      The maximum capacity of the default queue. 
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.state</name>
    <value>RUNNING</value>
    <description>
      The state of the default queue. State can be one of RUNNING or STOPPED.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
    <value>*</value>
    <description>
      The ACL of who can submit jobs to the default queue.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
    <value>*</value>
    <description>
      The ACL of who can administer jobs on the default queue.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.root.default.acl_application_max_priority</name>
    <value>*</value>
    <description>
      The ACL of who can submit applications with configured priority.
      For e.g, [user={name} group={name} max_priority={priority} default_priority={priority}]
    </description>
  </property>

   <property>
     <name>yarn.scheduler.capacity.root.default.maximum-application-lifetime
     </name>
     <value>-1</value>
     <description>
        Maximum lifetime of an application which is submitted to a queue
        in seconds. Any value less than or equal to zero will be considered as
        disabled.
        This will be a hard time limit for all applications in this
        queue. If positive value is configured then any application submitted
        to this queue will be killed after exceeds the configured lifetime.
        User can also specify lifetime per application basis in
        application submission context. But user lifetime will be
        overridden if it exceeds queue maximum lifetime. It is point-in-time
        configuration.
        Note : Configuring too low value will result in killing application
        sooner. This feature is applicable only for leaf queue.
     </description>
   </property>

   <property>
     <name>yarn.scheduler.capacity.root.default.default-application-lifetime
     </name>
     <value>-1</value>
     <description>
        Default lifetime of an application which is submitted to a queue
        in seconds. Any value less than or equal to zero will be considered as
        disabled.
        If the user has not submitted application with lifetime value then this
        value will be taken. It is point-in-time configuration.
        Note : Default lifetime can't exceed maximum lifetime. This feature is
        applicable only for leaf queue.
     </description>
   </property>

  <property>
    <name>yarn.scheduler.capacity.node-locality-delay</name>
    <value>40</value>
    <description>
      Number of missed scheduling opportunities after which the CapacityScheduler 
      attempts to schedule rack-local containers.
      When setting this parameter, the size of the cluster should be taken into account.
      We use 40 as the default value, which is approximately the number of nodes in one rack.
      Note, if this value is -1, the locality constraint in the container request
      will be ignored, which disables the delay scheduling.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.rack-locality-additional-delay</name>
    <value>-1</value>
    <description>
      Number of additional missed scheduling opportunities over the node-locality-delay
      ones, after which the CapacityScheduler attempts to schedule off-switch containers,
      instead of rack-local ones.
      Example: with node-locality-delay=40 and rack-locality-delay=20, the scheduler will
      attempt rack-local assignments after 40 missed opportunities, and off-switch assignments
      after 40+20=60 missed opportunities.
      When setting this parameter, the size of the cluster should be taken into account.
      We use -1 as the default value, which disables this feature. In this case, the number
      of missed opportunities for assigning off-switch containers is calculated based on
      the number of containers and unique locations specified in the resource request,
      as well as the size of the cluster.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.queue-mappings</name>
    <value></value>
    <description>
      A list of mappings that will be used to assign jobs to queues
      The syntax for this list is [u|g]:[name]:[queue_name][,next mapping]*
      Typically this list will be used to map users to queues,
      for example, u:%user:%user maps all users to queues with the same name
      as the user.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.queue-mappings-override.enable</name>
    <value>false</value>
    <description>
      If a queue mapping is present, will it override the value specified
      by the user? This can be used by administrators to place jobs in queues
      that are different than the one specified by the user.
      The default is false.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.per-node-heartbeat.maximum-offswitch-assignments</name>
    <value>1</value>
    <description>
      Controls the number of OFF_SWITCH assignments allowed
      during a node's heartbeat. Increasing this value can improve
      scheduling rate for OFF_SWITCH containers. Lower values reduce
      "clumping" of applications on particular nodes. The default is 1.
      Legal values are 1-MAX_INT. This config is refreshable.
    </description>
  </property>


  <property>
    <name>yarn.scheduler.capacity.application.fail-fast</name>
    <value>false</value>
    <description>
      Whether RM should fail during recovery if previous applications'
      queue is no longer valid.
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.workflow-priority-mappings</name>
    <value></value>
    <description>
      A list of mappings that will be used to override application priority.
      The syntax for this list is
      [workflowId]:[full_queue_name]:[priority][,next mapping]*
      where an application submitted (or mapped to) queue "full_queue_name"
      and workflowId "workflowId" (as specified in application submission
      context) will be given priority "priority".
    </description>
  </property>

  <property>
    <name>yarn.scheduler.capacity.workflow-priority-mappings-override.enable</name>
    <value>false</value>
    <description>
      If a priority mapping is present, will it override the value specified
      by the user? This can be used by administrators to give applications a
      priority that is different than the one specified by the user.
      The default is false.
    </description>
  </property>

</configuration>
5.5.5.1.3配置spark
5.5.5.1.3.1spark-default.xml
Bash
spark.authenticate=false
spark.driver.log.dfsDir=/user/spark/driverLogs
spark.driver.log.persistToDfs.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60
spark.dynamicAllocation.minExecutors=0
spark.dynamicAllocation.maxExecutors=20
spark.dynamicAllocation.schedulerBacklogTimeout=1
spark.eventLog.enabled=true
spark.io.encryption.enabled=false
spark.network.crypto.enabled=false
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.shuffle.service.enabled=true
spark.shuffle.service.port=7337
spark.shuffle.manager=sort
#spark.shuffle.manager=yarn
spark.shuffle.memoryFraction=0.4
spark.shuffle.spill=false
spark.shuffle.compress=true
spark.shuffle.compress.codec=lz4
spark.ui.enabled=true
spark.ui.killEnabled=true
spark.lineage.log.dir=/var/log/spark/lineage
spark.lineage.enabled=true
spark.master=yarn
spark.submit.deployMode=client
spark.yarn.historyServer.address=http://hadoop3:18088
spark.yarn.historyServer.allowTracking=true
spark.eventLog.dir=hdfs://hadoop3:2220/user/spark/applicationHistory
spark.executor.extraJavaOptions=-XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
spark.yarn.containerLauncherMaxThreads=100
#spark.yarn.archive=hdfs://hadoop3:2220/user/spark/jars/spark-libs.jar
spark.yarn.appMasterEnv.MKL_NUM_THREADS=1
spark.executorEnv.MKL_NUM_THREADS=1
spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS=1
spark.executorEnv.OPENBLAS_NUM_THREADS=1
spark.driver.extraLibraryPath=/home/hadoop/core/lib/native
spark.executor.extraLibraryPath=/home/hadoop/core/lib/native/
spark.yarn.am.extraLibraryPath=/home/hadoop/core/lib/native/
spark.pyspark.python=/usr/bin/python3.7
spark.pyspark.driver.python=/usr/bin/python3.7
spark.sql.warehouse.dir=/user/hive/warehouse
#spark.sql.hive.metastore.jars=/home/hadoop/hive/lib/*
#spark.sql.hive.metastore.version=3.1.2
spark.jars.packages=org.apache.iceberg:iceberg-spark-runtime:0.13.1
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
#spark.sql.catalog.local.type=hadoop
spark.sql.catalog.local.warehouse=/user/hive/warehouse
#spark.sql.defaultCatalog=local
spark.sql.catalogImplementation=hive
5.5.5.1.3.2spark-env.sh
Bash
#!/usr/bin/env bash
##
# Generated by Cloudera Manager and should not be modified directly
##
export SPARK_HOME=/home/hadoop/spark

export HADOOP_HOME=/home/hadoop/core

export HADOOP_COMMON_HOME="$HADOOP_HOME"

export SPARK_WORKER_MEMORY=1024MB

#export spark.yarn.archive=hdfs://hadoop3:2220/user/spark/jars/spark-libs.jar
export SPARK_DRIVER_MEMORY=5G

export SPARK_BEELINE_MEMORY=1024MB
export SPARK_EXECUTOR_MEMORY=1024MB
export SPARK_MASTER_HOST=hadoop2
export SPARK_MASTER_PORT=7077

PYLIB="$SPARK_HOME/python/lib"
if [ -f "$PYLIB/pyspark.zip" ]; then
  PYSPARK_ARCHIVES_PATH=
  for lib in "$PYLIB"/*.zip; do
    if [ -n "$PYSPARK_ARCHIVES_PATH" ]; then
      PYSPARK_ARCHIVES_PATH="$PYSPARK_ARCHIVES_PATH,local:$lib"
    else
      PYSPARK_ARCHIVES_PATH="local:$lib"
    fi
  done
  export PYSPARK_ARCHIVES_PATH
fi
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib//native

export SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=hdfs://hadoop3:2220/sparklog/ -Dspark.history.fs.cleaner.enabled=true"
5.5.5.1.4配置zookeeper
5.5.5.1.4.1zoo.cfg
Bash
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/home/hadoop/zookeeper/data
# the port at which the clients will connect
clientPort=2281
server.0=hadoop0:2288:2388
server.1=hadoop1:2288:2388
server.2=hadoop2:2288:2388
server.3=hadoop3:2288:2388
server.4=hadoop4:2288:2388
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1

## Metrics Providers
#
# https://prometheus.io Metrics Exporter
#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
#metricsProvider.httpHost=0.0.0.0
#metricsProvider.httpPort=7000
#metricsProvider.exportJvmInfo=true

5.5.5.1.5配置kafka集群
Bash
hostname  phy212配置
broker.id=0
listeners = PLAINTEXT://10.68.23.83:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/hadoop/kafka/logs/
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=hadoop0:2281,hadoop1:2281,hadoop2:2281,hadoop3:2281,hadoop4:2281
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0

hostname  phy213配置
broker.id=1
listeners = PLAINTEXT://10.68.23.84:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/hadoop/kafka/logs/
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=hadoop0:2281,hadoop1:2281,hadoop2:2281,hadoop3:2281,hadoop4:2281
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0

hostname  phy214配置
broker.id=2
listeners = PLAINTEXT://10.68.23.85:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/home/hadoop/kafka/logs/
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=hadoop0:2281,hadoop1:2281,hadoop2:2281,hadoop3:2281,hadoop4:2281
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
5.5.5.2数据仓&数据库配置
5.5.5.2.1配置hive
5.5.5.2.1.11.hive-site.xml
Bash
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://hadoop2:2206/hivestore</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hiveMeta@987</value>
  </property>

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/hive/warehouse</value>
  </property>

  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
  </property>
 
  <property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.warehouse.subdir.inherit.perms</name>
    <value>true</value>
  </property>
 
  <property>
    <name>hive.auto.convert.join</name>
    <value>true</value>
  </property>
 
  <property>
    <name>hive.metastore.port</name>
    <value>2299</value>
  </property>
 
  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://hadoop2:2299</value>
  </property>

  <property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.metastore.authorization.storage.checks</name>
    <value>true</value>
  </property>
  
  <property>
    <name>hive.server2.thrift.min.worker.threads</name>
    <value>10</value>
  </property>

  <property>
    <name>hive.server2.thrift.max.worker.threads</name>
    <value>2048</value>
  </property>

  <property>
    <name>hive.server2.thrift.port</name>
    <value>2245</value>
  </property>

  <property>
    <name>hive.server2.thrift.http.port</name>
    <value>2244</value>
  </property>

  <property>
    <name>hive.server2.webui.port</name>
    <value>2246</value>
  </property>
 
  <property>
    <name>hive.server2.authentication</name>
    <value>NONE</value>
  </property>

  <property>  
    <name>hive.server2.zookeeper.namespace</name>  
    <value>/hive/server2</value>
  </property>

  <property>
    <name>hive.execution.engine</name>
    <value>mr</value>
  </property>

   <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/home/hadoop/hive/log-operation</value>
  </property>

  <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
  </property>
 #配置优化 
  <property>
    <name>hive.fetch.task.conversion.threshold</name>
    <value>268435456</value>
  </property>
  
  <property>
    <name>hive.limit.pushdown.memory.usage</name>
    <value>0.1</value>
  </property>
  
  <property>
    <name>hive.merge.smallfiles.avgsize</name>
    <value>16777216</value>
  </property>
  
  <property>
    <name>hive.merge.size.per.task</name>
    <value>268435456</value>
  </property>
  
  <property>
    <name>hive.optimize.reducededuplication</name>
    <value>true</value>
  </property>

  <property>
    <name>spark.shuffle.service.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.auto.convert.join</name>
    <value>true</value>
  </property>
<!--
  <property>
    <name>hive.support.index</name>
    <value>true</value>
  </property>
  -->
  <property>
    <name>hive.exec.parallel</name>
    <value>true</value>
  </property>

  <property>
    <name>hive.server2.service.users</name>
    <value>hadoop,hive,deploy,spark</value>
    <description>Comma separated list of users to have HiveServer2 skip authorization when compiling queries.</description>
  </property>
  <property>
    <name>hive.distcp.privileged.doAs</name>
    <value>hadoop</value>
    <description>
      This property allows privileged distcp executions done by hive to run as this user.
    </description>
  </property>

  <property>
    <name>hive.users.in.admin.role</name>
    <value>hadoop,hive,deploy,spark</value>
  </property>

  <property>
    <name>hive.server2.trusted.domain</name>
    <value>hadoop0,hadoop1,hadoop2,hadoop3,hadoop4</value>
  </property>
 
</configuration>

5.5.5.2.1.2安装mysql
Bash
yum -y install mysql
5.5.5.2.1.2.1mysql配置
Bash
vim /home/hadoop/mysql/conf/my.cnf
[mysqld]
user=root
bind-address=0.0.0.0
port=2206
# basedir=/home/hadoop/mysql
pid-file=mysql.pid
log-error=error.log
socket=mysql.sock
character-set-server=utf8mb4
secure_file_priv=./
expire_logs_days=7
sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION
max_connections=1000
lower_case_table_names=1

[client]
default-character-set=utf8mb4

[mysql]
default-character-set=utf8mb4
5.5.5.2.1.3创建hivestore数据库并授权
Bash
CREATE DATABASE hivestore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
GRANT ALL ON hivestore.* TO 'hive'@'%' IDENTIFIED BY 'hiveMeta@987';
5.5.5.2.1.4初始化hive仓
Bash
Cd /home/hadoop/hive/bin
Schematool -initSchema  -dbType mysql -verbos
5.5.5.2.1.5格式化namenode
Bash
hdfs namenode -format
5.5.6 启动集群
Bash
cd  zookeeper/bin  && ./zkServer.sh    ##启动zookeeper
cd core/sbin                           ##进入hadoop目录
./hadoop-daemon.sh start journalnode   ## 启动所有部署有hadoop机器都需要  start journalnode  
./start-all.sh                         ##启动 hadooop和yarn
./hadoop-daemon.sh start  zkfc         ##启动namenode所在的机器
hive --service matestore               ##启动 matestore
hive --service hiveserver2             ##启动  hiveserver2
cd spark/sbin                          ##进入spark目录
./start-master.sh                      ##启动spark
start-mesos-shuffle-service.sh         ##启动spark-shuffle
./kafka-server-start.sh -daemon ../config/server.properties       ##启动kafka
5.6超算力数据中台部署
5.6.1平台配置更新 
JSON
#交互式，默认参数通过/etc/hosts获取主机名解析地址 
cd /data/shuqi/install && sh update_variable.sh 
5.6.1.1平台环境变量配置更新 
Bash
#请按需修改变量值，如：MEM、SHUXI_USER 
cd /data/shuqi/install 
vim bashrc 
5.6.1.2安装包分发 
Bash
cd /data/shuqi/install && sh rsync.sh 
5.6.2中间件部署 
5.6.2.1shuqi1节点组件安装 
Plain Text
ssh shuqi1 "sh /opt/third/install/install_nginx.sh" 
ssh shuqi1 "sh /opt/third/install/install_filebeat.sh" 
5.6.2.2shuqidb节点组件安装 
Plain Text
#mysql 
ssh shuqidb "sh /opt/third/install/init_shuqidb.sh" 
#如es需要配置集群，结合「附件⼀」中具体操作流程设置 
麒麟v10 mysql安装失败，SQL未导⼊ Registry未启动,需⼿动处理。 
5.6.2.3 shuqi2节点组件安装 
Plain Text
ssh shuqi2 "sh /opt/third/install/install_grafana.sh" 
ssh shuqi2 "sh /opt/third/install/install_prometheus.sh" 
ssh shuqi2 "sh /opt/third/install/install_filebeat.sh" 
5.6.2.4shuqi3节点组件安装 
Plain Text
ssh shuqi3 "sh /opt/third/install/install_node_exporter.sh" 
ssh shuqi3 "sh /opt/third/install/install_pushgateway.sh" 
#flink(资产模块需要) 
ssh shuqi3 "su - deploy -c 'cd /opt/third/flink/bin/ && ./start-cluster.sh'" 
5.6.3平台启动 
5.6.3.1数据中台服务启动 
#启动 
ssh shuqi1 "su - deploy -c 'sh /home/deploy/auto_start/startService.sh'" 
ssh shuqi2 "su - deploy -c 'sh /home/deploy/auto_start/startService.sh'" 
ssh shuqi3 "su - deploy -c 'sh /home/deploy/auto_start/startService.sh'" 
#停⽌ 
ssh shuqi1 "su - deploy -c 'sh /home/deploy/auto_start/stopAllService.sh'" 
ssh shuqi2 "su - deploy -c 'sh /home/deploy/auto_start/stopAllService.sh'" 
ssh shuqi3 "su - deploy -c 'sh /home/deploy/auto_start/stopAllService.sh'" 
6注意事项
6.1前提条件
6.1.1环境前提条件
(1)系统兼容性：确保所有相关软件和硬件系统与项目要求兼容。
(2)技术熟练度：项目团队成员应具备必要的技术知识和技能。
(3)网络环境：具备稳定、高速的网络连接，以满足数据传输和通信需求。
(4)物理环境：确保设备硬件正常工作没有告警。
6.2限制与约束
6.2.1资源限制
6.2.1.1硬件资源配置
6.2.1.1.1服务器性能
(1)确保服务器具有足够的CPU、内存和存储空间，以满足集群的负载需求。
(2)选择高性能的服务器硬件，如SSD硬盘，以提高读写速度和整体性能。
6.2.1.1.2网络配置
(1)确保集群中的所有节点都能够通过高速网络连接，且网络延迟较低。
(2)配置足够的网络带宽，以支持高吞吐量的数据传输。
6.2.1.2软件配置
(1)确保所有节点上的操作系统配置一致，以避免兼容性问题。
(2)根据集群规模和应用需求，合理配置集群软件的参数和选项。
(3)确保所有节点上安装的依赖服务配置正确且能够正常运行。
(4)定期检查和维护依赖服务的状态，以确保集群的稳定运行。
6.2.1.2.1集群配置
6.2.1.2.1.1节点配置
(1)确保集群中的所有节点都配置了正确的IP地址和主机名。
(2)使用静态IP地址，以避免IP地址冲突和网络连接问题。
6.2.1.2.1.2负载均衡
(1)配置负载均衡器以均衡集群中的负载，提高资源利用率和响应时间。
(2)根据应用需求选择合适的负载均衡算法和策略。
6.2.1.2.1.3数据备份和恢复
(1)定期备份集群中的重要数据，以防止数据丢失或损坏。
(2)配置数据恢复策略，以便在数据丢失时能够迅速恢复。
6.2.1.2.1.4安全性配置
(1)配置网络安全策略，如防火墙规则、入侵检测系统等，以确保集群的安全。
(2)对集群中的敏感数据进行加密处理，以保护数据安全。






7附录
7.1参考文档
https://hadoop.apache.org/
https://hive.apache.org/
https://spark.apache.org/
https://flink.apache.org/
https://kafka.apache.org/
https://zookeeper.apache.org/


